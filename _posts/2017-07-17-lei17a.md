---
title: Deriving Neural Architectures from Sequence and Graph Kernels
booktitle: Proceedings of the 34th International Conference on Machine Learning
year: '2017'
volume: '70'
series: Proceedings of Machine Learning Research
address: 
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v70/lei17a/lei17a.pdf
url: http://proceedings.mlr.press/v70/lei17a.html
abstract: The design of neural architectures for structured objects is typically guided
  by experimental insights rather than a formal process. In this work, we appeal to
  kernels over combinatorial structures, such as sequences and graphs, to derive appropriate
  neural operations. We introduce a class of deep recurrent neural operations and
  formally characterize their associated kernel spaces. Our recurrent modules compare
  the input to virtual reference objects (cf. filters in CNN) via the kernels. Similar
  to traditional neural operations, these reference objects are parameterized and
  directly optimized in end-to-end training. We empirically evaluate the proposed
  class of neural architectures on standard applications such as language modeling
  and molecular graph regression, achieving state-of-the-art results across these
  applications.
layout: inproceedings
id: lei17a
tex_title: Deriving Neural Architectures from Sequence and Graph Kernels
firstpage: 2024
lastpage: 2033
page: 2024-2033
order: 2024
cycles: false
editor:
- given: Doina
  family: Precup
- given: Yee Whye
  family: Teh
author:
- given: Tao
  family: Lei
- given: Wengong
  family: Jin
- given: Regina
  family: Barzilay
- given: Tommi
  family: Jaakkola
date: 2017-07-17
container-title: Proceedings of the 34th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 7
  - 17
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
