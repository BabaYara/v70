---
title: Reinforcement Learning with Deep Energy-Based Policies
booktitle: Proceedings of the 34th International Conference on Machine Learning
year: '2017'
volume: '70'
series: Proceedings of Machine Learning Research
address: 
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v70/haarnoja17a/haarnoja17a.pdf
url: http://proceedings.mlr.press/v70/haarnoja17a.html
abstract: We propose a method for learning expressive energy-based policies for continuous
  states and actions, which has been feasible only in tabular domains before. We apply
  our method to learning maximum entropy policies, resulting into a new algorithm,
  called soft Q-learning, that expresses the optimal policy via a Boltzmann distribution.
  We use the recently proposed amortized Stein variational gradient descent to learn
  a stochastic sampling network that approximates samples from this distribution.
  The benefits of the proposed algorithm include improved exploration and compositionality
  that allows transferring skills between tasks, which we confirm in simulated experiments
  with swimming and walking robots. We also draw a connection to actor-critic methods,
  which can be viewed performing approximate inference on the corresponding energy-based
  model.
layout: inproceedings
id: haarnoja17a
tex_title: Reinforcement Learning with Deep Energy-Based Policies
firstpage: 1352
lastpage: 1361
page: 1352-1361
order: 1352
cycles: false
editor:
- given: Doina
  family: Precup
- given: Yee Whye
  family: Teh
author:
- given: Tuomas
  family: Haarnoja
- given: Haoran
  family: Tang
- given: Pieter
  family: Abbeel
- given: Sergey
  family: Levine
date: 2017-07-17
container-title: Proceedings of the 34th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 7
  - 17
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v70/haarnoja17a/haarnoja17a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
