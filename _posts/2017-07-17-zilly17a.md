---
title: Recurrent Highway Networks
booktitle: Proceedings of the 34th International Conference on Machine Learning
year: '2017'
volume: '70'
series: Proceedings of Machine Learning Research
address: 
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v70/zilly17a/zilly17a.pdf
url: http://proceedings.mlr.press/v70/zilly17.html
abstract: Many sequential processing tasks require complex nonlinear transition functions
  from one step to the next. However, recurrent neural networks with “deep” transition
  functions remain difficult to train, even when using Long Short-Term Memory (LSTM)
  networks. We introduce a novel theoretical analysis of recurrent networks based
  on Gersgorin’s circle theorem that illuminates several modeling and optimization
  issues and improves our understanding of the LSTM cell. Based on this analysis we
  propose Recurrent Highway Networks, which extend the LSTM architecture to allow
  step-to-step transition depths larger than one. Several language modeling experiments
  demonstrate that the proposed architecture results in powerful and efficient models.
  On the Penn Treebank corpus, solely increasing the transition depth from 1 to 10
  improves word-level perplexity from 90.6 to 65.4 using the same number of parameters.
  On the larger Wikipedia datasets for character prediction (text8 and enwik8), RHNs
  outperform all previous results and achieve an entropy of 1.27 bits per character.
layout: inproceedings
id: zilly17a
tex_title: Recurrent Highway Networks
firstpage: 4189
lastpage: 4198
page: 4189-4198
order: 4189
cycles: false
editor:
- given: Doina
  family: Precup
- given: Yee Whye
  family: Teh
author:
- given: Julian Georg
  family: Zilly
- given: Rupesh Kumar
  family: Srivastava
- given: Jan
  family: Koutnı́k
- given: Jürgen
  family: Schmidhuber
date: 2017-07-17
container-title: Proceedings of the 34th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 7
  - 17
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v70/zilly17a/zilly17a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
