---
title: Efficient Distributed Learning with Sparsity
booktitle: Proceedings of the 34th International Conference on Machine Learning
year: '2017'
volume: '70'
series: Proceedings of Machine Learning Research
address: 
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v70/wang17f/wang17f.pdf
url: http://proceedings.mlr.press/v70/wang17f.html
abstract: We propose a novel, efficient approach for distributed sparse learning with
  observations randomly partitioned across machines. In each round of the proposed
  method, worker machines compute the gradient of the loss on local data and the master
  machine solves a shifted $\ell_1$ regularized loss minimization problem. After a
  number of communication rounds that scales only logarithmically with the number
  of machines, and independent of other parameters of the problem, the proposed approach
  provably matches the estimation error bound of centralized methods.
layout: inproceedings
id: wang17f
tex_title: Efficient Distributed Learning with Sparsity
firstpage: 3636
lastpage: 3645
page: 3636-3645
order: 3636
cycles: false
editor:
- given: Doina
  family: Precup
- given: Yee Whye
  family: Teh
author:
- given: Jialei
  family: Wang
- given: Mladen
  family: Kolar
- given: Nathan
  family: Srebro
- given: Tong
  family: Zhang
date: 2017-07-17
container-title: Proceedings of the 34th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 7
  - 17
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v70/wang17f/wang17f-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
