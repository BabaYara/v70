---
title: 'meProp: Sparsified Back Propagation for Accelerated Deep Learning with Reduced
  Overfitting'
booktitle: Proceedings of the 34th International Conference on Machine Learning
year: '2017'
volume: '70'
series: Proceedings of Machine Learning Research
address: 
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v70/sun17c/sun17c.pdf
url: http://proceedings.mlr.press/v70/sun17c.html
abstract: We propose a simple yet effective technique for neural network learning.
  The forward propagation is computed as usual. In back propagation, only a small
  subset of the full gradient is computed to update the model parameters. The gradient
  vectors are sparsified in such a way that only the top-$k$ elements (in terms of
  magnitude) are kept. As a result, only $k$ rows or columns (depending on the layout)
  of the weight matrix are modified, leading to a linear reduction ($k$ divided by
  the vector dimension) in the computational cost. Surprisingly, experimental results
  demonstrate that we can update only 1â€“4\% of the weights at each back propagation
  pass. This does not result in a larger number of training iterations. More interestingly,
  the accuracy of the resulting models is actually improved rather than degraded,
  and a detailed analysis is given.
layout: inproceedings
id: sun17c
tex_title: 'me{P}rop: Sparsified Back Propagation for Accelerated Deep Learning with
  Reduced Overfitting'
firstpage: 3299
lastpage: 3308
page: 3299-3308
order: 3299
cycles: false
editor:
- given: Doina
  family: Precup
- given: Yee Whye
  family: Teh
author:
- given: Xu
  family: Sun
- given: Xuancheng
  family: Ren
- given: Shuming
  family: Ma
- given: Houfeng
  family: Wang
date: 2017-07-17
container-title: Proceedings of the 34th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 7
  - 17
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
