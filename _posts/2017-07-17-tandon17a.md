---
title: 'Gradient Coding: Avoiding Stragglers in Distributed Learning'
booktitle: Proceedings of the 34th International Conference on Machine Learning
year: '2017'
volume: '70'
series: Proceedings of Machine Learning Research
address: 
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v70/tandon17a/tandon17a.pdf
url: http://proceedings.mlr.press/v70/tandon17a.html
abstract: We propose a novel coding theoretic framework for mitigating stragglers
  in distributed learning. We show how carefully replicating data blocks and coding
  across gradients can provide tolerance to failures and stragglers for synchronous
  Gradient Descent. We implement our schemes in python (using MPI) to run on Amazon
  EC2, and show how we compare against baseline approaches in running time and generalization
  error.
layout: inproceedings
id: tandon17a
tex_title: 'Gradient Coding: Avoiding Stragglers in Distributed Learning'
bibtex_author: Rashish Tandon and Qi Lei and Alexandros G. Dimakis and Nikos Karampatziakis
firstpage: 3368
lastpage: 3376
page: 3368-3376
order: 3368
cycles: false
editor:
- given: Doina
  family: Precup
- given: Yee Whye
  family: Teh
author:
- given: Rashish
  family: Tandon
- given: Qi
  family: Lei
- given: Alexandros G.
  family: Dimakis
- given: Nikos
  family: Karampatziakis
date: 2017-07-17
container-title: Proceedings of the 34th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 7
  - 17
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v70/tandon17a/tandon17a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
