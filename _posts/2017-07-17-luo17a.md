---
title: Learning Deep Architectures via Generalized Whitened Neural Networks
booktitle: Proceedings of the 34th International Conference on Machine Learning
year: '2017'
volume: '70'
series: Proceedings of Machine Learning Research
address: 
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v70/luo17a/luo17a.pdf
url: http://proceedings.mlr.press/v70/luo17a.html
abstract: Whitened Neural Network (WNN) is a recent advanced deep architecture, which
  improves convergence and generalization of canonical neural networks by whitening
  their internal hidden representation. However, the whitening transformation increases
  computation time. Unlike WNN that reduced runtime by performing whitening every
  thousand iterations, which degenerates convergence due to the ill conditioning,
  we present generalized WNN (GWNN), which has three appealing properties. First,
  GWNN is able to learn compact representation to reduce computations. Second, it
  enables whitening transformation to be performed in a short period, preserving good
  conditioning. Third, we propose a data-independent estimation of the covariance
  matrix to further improve computational efficiency. Extensive experiments on various
  datasets demonstrate the benefits of GWNN.
layout: inproceedings
id: luo17a
tex_title: Learning Deep Architectures via Generalized Whitened Neural Networks
firstpage: 2238
lastpage: 2246
page: 2238-2246
order: 2238
cycles: false
editor:
- given: Doina
  family: Precup
- given: Yee Whye
  family: Teh
author:
- given: Ping
  family: Luo
date: 2017-07-17
container-title: Proceedings of the 34th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 7
  - 17
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
