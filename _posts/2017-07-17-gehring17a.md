---
title: Convolutional Sequence to Sequence Learning
booktitle: Proceedings of the 34th International Conference on Machine Learning
year: '2017'
volume: '70'
series: Proceedings of Machine Learning Research
address: 
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v70/gehring17a/gehring17a.pdf
url: http://proceedings.mlr.press/v70/gehring17a.html
abstract: The prevalent approach to sequence to sequence learning maps an input sequence
  to a variable length output sequence via recurrent neural networks. We introduce
  an architecture based entirely on convolutional neural networks. Compared to recurrent
  models, computations over all elements can be fully parallelized during training
  to better exploit the GPU hardware and optimization is easier since the number of
  non-linearities is fixed and independent of the input length. Our use of gated linear
  units eases gradient propagation and we equip each decoder layer with a separate
  attention module. We outperform the accuracy of the deep LSTM setup of Wu et al.
  (2016) on both WMT’14 English-German and WMT’14 English-French translation at an
  order of magnitude faster speed, both on GPU and CPU.
layout: inproceedings
id: gehring17a
tex_title: Convolutional Sequence to Sequence Learning
firstpage: 1243
lastpage: 1252
page: 1243-1252
order: 1243
cycles: false
editor:
- given: Doina
  family: Precup
- given: Yee Whye
  family: Teh
author:
- given: Jonas
  family: Gehring
- given: Michael
  family: Auli
- given: David
  family: Grangier
- given: Denis
  family: Yarats
- given: Yann N.
  family: Dauphin
date: 2017-07-17
container-title: Proceedings of the 34th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 7
  - 17
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v70/gehring17a/gehring17a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
