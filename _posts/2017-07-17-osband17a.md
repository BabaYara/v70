---
title: Why is Posterior Sampling Better than Optimism for Reinforcement Learning?
booktitle: Proceedings of the 34th International Conference on Machine Learning
year: '2017'
volume: '70'
series: Proceedings of Machine Learning Research
address: 
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v70/osband17a/osband17a.pdf
url: http://proceedings.mlr.press/v70/osband17a.html
abstract: Computational results demonstrate that posterior sampling for reinforcement
  learning (PSRL) dramatically outperforms existing algorithms driven by optimism,
  such as UCRL2. We provide insight into the extent of this performance boost and
  the phenomenon that drives it. We leverage this insight to establish an $\tilde{O}(H\sqrt{SAT})$
  Bayesian regret bound for PSRL in finite-horizon episodic Markov decision processes.
  This improves upon the best previous Bayesian regret bound of $\tilde{O}(H S \sqrt{AT})$
  for any reinforcement learning algorithm. Our theoretical results are supported
  by extensive empirical evaluation.
layout: inproceedings
id: osband17a
tex_title: Why is Posterior Sampling Better than Optimism for Reinforcement Learning?
firstpage: 2701
lastpage: 2710
page: 2701-2710
order: 2701
cycles: false
editor:
- given: Doina
  family: Precup
- given: Yee Whye
  family: Teh
author:
- given: Ian
  family: Osband
- given: Benjamin
  family: Van Roy
date: 2017-07-17
container-title: Proceedings of the 34th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 7
  - 17
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v70/osband17a/osband17a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
