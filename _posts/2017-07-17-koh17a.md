---
title: Understanding Black-box Predictions via Influence Functions
booktitle: Proceedings of the 34th International Conference on Machine Learning
year: '2017'
volume: '70'
series: Proceedings of Machine Learning Research
address: 
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v70/koh17a/koh17a.pdf
url: http://proceedings.mlr.press/v70/koh17.html
abstract: 'How can we explain the predictions of a black-box model? In this paper,
  we use influence functions — a classic technique from robust statistics — to trace
  a model’s prediction through the learning algorithm and back to its training data,
  thereby identifying training points most responsible for a given prediction. To
  scale up influence functions to modern machine learning settings, we develop a simple,
  efficient implementation that requires only oracle access to gradients and Hessian-vector
  products. We show that even on non-convex and non-differentiable models where the
  theory breaks down, approximations to influence functions can still provide valuable
  information. On linear models and convolutional neural networks, we demonstrate
  that influence functions are useful for multiple purposes: understanding model behavior,
  debugging models, detecting dataset errors, and even creating visually-indistinguishable
  training-set attacks.'
layout: inproceedings
id: koh17a
tex_title: Understanding Black-box Predictions via Influence Functions
firstpage: 1885
lastpage: 1894
page: 1885-1894
order: 1885
cycles: false
editor:
- given: Doina
  family: Precup
- given: Yee Whye
  family: Teh
author:
- given: Pang Wei
  family: Koh
- given: Percy
  family: Liang
date: 2017-07-17
container-title: Proceedings of the 34th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 7
  - 17
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v70/koh17a/koh17a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
