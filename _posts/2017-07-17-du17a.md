---
title: Stochastic Variance Reduction Methods for Policy Evaluation
booktitle: Proceedings of the 34th International Conference on Machine Learning
year: '2017'
volume: '70'
series: Proceedings of Machine Learning Research
address: 
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v70/du17a/du17a.pdf
url: http://proceedings.mlr.press/v70/du17.html
abstract: Policy evaluation is concerned with estimating the value function that predicts
  long-term values of states under a given policy. It is a crucial step in many reinforcement-learning
  algorithms. In this paper, we focus on policy evaluation with linear function approximation
  over a fixed dataset. We first transform the empirical policy evaluation problem
  into a (quadratic) convex-concave saddle-point problem, and then present a primal-dual
  batch gradient method, as well as two stochastic variance reduction methods for
  solving the problem. These algorithms scale linearly in both sample size and feature
  dimension. Moreover, they achieve linear convergence even when the saddle-point
  problem has only strong concavity in the dual variables but no strong convexity
  in the primal variables. Numerical experiments on benchmark problems demonstrate
  the effectiveness of our methods.
layout: inproceedings
id: du17a
tex_title: Stochastic Variance Reduction Methods for Policy Evaluation
firstpage: 1049
lastpage: 1058
page: 1049-1058
order: 1049
cycles: false
editor:
- given: Doina
  family: Precup
- given: Yee Whye
  family: Teh
author:
- given: Simon S.
  family: Du
- given: Jianshu
  family: Chen
- given: Lihong
  family: Li
- given: Lin
  family: Xiao
- given: Dengyong
  family: Zhou
date: 2017-07-17
container-title: Proceedings of the 34th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 7
  - 17
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v70/du17a/du17a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
