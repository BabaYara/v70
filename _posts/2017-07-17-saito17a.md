---
title: Asymmetric Tri-training for Unsupervised Domain Adaptation
booktitle: Proceedings of the 34th International Conference on Machine Learning
year: '2017'
volume: '70'
series: Proceedings of Machine Learning Research
address: 
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v70/saito17a/saito17a.pdf
url: http://proceedings.mlr.press/v70/saito17a.html
abstract: It is important to apply models trained on a large number of labeled samples
  to different domains because collecting many labeled samples in various domains
  is expensive. To learn discriminative representations for the target domain, we
  assume that artificially labeling the target samples can result in a good representation.
  Tri-training leverages three classifiers equally to provide pseudo-labels to unlabeled
  samples; however, the method does not assume labeling samples generated from a different
  domain. In this paper, we propose the use of an \emphasymmetric tri-training method
  for unsupervised domain adaptation, where we assign pseudo-labels to unlabeled samples
  and train the neural networks as if they are true labels. In our work, we use three
  networks \emphasymmetrically, and by \emphasymmetric, we mean that two networks
  are used to label unlabeled target samples, and one network is trained by the pseudo-labeled
  samples to obtain target-discriminative representations. Our proposed method was
  shown to achieve a state-of-the-art performance on the benchmark digit recognition
  datasets for domain adaptation.
layout: inproceedings
id: saito17a
tex_title: Asymmetric Tri-training for Unsupervised Domain Adaptation
firstpage: 2988
lastpage: 2997
page: 2988-2997
order: 2988
cycles: false
editor:
- given: Doina
  family: Precup
- given: Yee Whye
  family: Teh
author:
- given: Kuniaki
  family: Saito
- given: Yoshitaka
  family: Ushiku
- given: Tatsuya
  family: Harada
date: 2017-07-17
container-title: Proceedings of the 34th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 7
  - 17
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v70/saito17a/saito17a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
