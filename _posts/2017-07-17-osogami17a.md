---
title: Bidirectional Learning for Time-series Models with Hidden Units
booktitle: Proceedings of the 34th International Conference on Machine Learning
year: '2017'
volume: '70'
series: Proceedings of Machine Learning Research
address: 
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v70/osogami17a/osogami17a.pdf
url: http://proceedings.mlr.press/v70/osogami17.html
abstract: Hidden units can play essential roles in modeling time-series having long-term
  dependency or on-linearity but make it difficult to learn associated parameters.
  Here we propose a way to learn such a time-series model by training a backward model
  for the time-reversed time-series, where the backward model has a common set of
  parameters as the original (forward) model. Our key observation is that only a subset
  of the parameters is hard to learn, and that subset is complementary between the
  forward model and the backward model. By training both of the two models, we can
  effectively learn the values of the parameters that are hard to learn if only either
  of the two models is trained. We apply bidirectional learning to a dynamic Boltzmann
  machine extended with hidden units. Numerical experiments with synthetic and real
  datasets clearly demonstrate advantages of bidirectional learning.
layout: inproceedings
id: osogami17a
tex_title: Bidirectional Learning for Time-series Models with Hidden Units
firstpage: 2711
lastpage: 2720
page: 2711-2720
order: 2711
cycles: false
editor:
- given: Doina
  family: Precup
- given: Yee Whye
  family: Teh
author:
- given: Takayuki
  family: Osogami
- given: Hiroshi
  family: Kajino
- given: Taro
  family: Sekiyama
date: 2017-07-17
container-title: Proceedings of the 34th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 7
  - 17
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v70/osogami17a/osogami17a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
