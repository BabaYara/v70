---
title: Dissipativity Theory for Nesterov’s Accelerated Method
booktitle: Proceedings of the 34th International Conference on Machine Learning
year: '2017'
volume: '70'
series: Proceedings of Machine Learning Research
address: 
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v70/hu17a/hu17a.pdf
url: http://proceedings.mlr.press/v70/hu17a.html
abstract: In this paper, we adapt the control theoretic concept of dissipativity theory
  to provide a natural understanding of Nesterov’s accelerated method. Our theory
  ties rigorous convergence rate analysis to the physically intuitive notion of energy
  dissipation. Moreover, dissipativity allows one to efficiently construct Lyapunov
  functions (either numerically or analytically) by solving a small semidefinite program.
  Using novel supply rate functions, we show how to recover known rate bounds for
  Nesterov’s method and we generalize the approach to certify both linear and sublinear
  rates in a variety of settings. Finally, we link the continuous-time version of
  dissipativity to recent works on algorithm analysis that use discretizations of
  ordinary differential equations.
layout: inproceedings
id: hu17a
tex_title: Dissipativity Theory for {N}esterov’s Accelerated Method
firstpage: 1549
lastpage: 1557
page: 1549-1557
order: 1549
cycles: false
editor:
- given: Doina
  family: Precup
- given: Yee Whye
  family: Teh
author:
- given: Bin
  family: Hu
- given: Laurent
  family: Lessard
date: 2017-07-17
container-title: Proceedings of the 34th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 7
  - 17
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v70/hu17a/hu17a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
