---
title: 'Natasha: Faster Non-Convex Stochastic Optimization via Strongly Non-Convex
  Parameter'
booktitle: Proceedings of the 34th International Conference on Machine Learning
year: '2017'
volume: '70'
series: Proceedings of Machine Learning Research
address: 
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v70/allen-zhu17a/allen-zhu17a.pdf
url: http://proceedings.mlr.press/v70/allen-zhu17a.html
abstract: 'Given a non-convex function $f(x)$ that is an average of $n$ smooth functions,
  we design stochastic first-order methods to find its approximate stationary points.
  The performance of our new methods depend on the smallest (negative) eigenvalue
  $-\sigma$ of the Hessian. This parameter $\sigma$ captures how strongly non-convex
  $f(x)$ is, and is analogous to the strong convexity parameter for convex optimization.
  At least in theory, our methods outperform known results for a range of parameter
  $\sigma$, and can also be used to find approximate local minima. Our result implies
  an interesting dichotomy: there exists a threshold $\sigma_0$ so that the (currently)
  fastest methods for $\sigma&gt;\sigma_0$ and for $\sigma&lt;\sigma_0$ have different
  behaviors: the former scales with $n^{2/3}$ and the latter scales with $n^{3/4}$.'
layout: inproceedings
id: allen-zhu17a
tex_title: 'Natasha: Faster Non-Convex Stochastic Optimization via Strongly Non-Convex
  Parameter'
bibtex_author: Zeyuan Allen-Zhu
firstpage: 89
lastpage: 97
page: 89-97
order: 89
cycles: false
editor:
- given: Doina
  family: Precup
- given: Yee Whye
  family: Teh
author:
- given: Zeyuan
  family: Allen-Zhu
date: 2017-07-17
container-title: Proceedings of the 34th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 7
  - 17
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
