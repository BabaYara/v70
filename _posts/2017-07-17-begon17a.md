---
title: 'Globally Induced Forest: A Prepruning Compression Scheme'
booktitle: Proceedings of the 34th International Conference on Machine Learning
year: '2017'
volume: '70'
series: Proceedings of Machine Learning Research
address: 
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v70/begon17a/begon17a.pdf
url: http://proceedings.mlr.press/v70/begon17.html
abstract: Tree-based ensemble models are heavy memory-wise. An undesired state of
  affairs considering nowadays datasets, memory-constrained environment and fitting/prediction
  times. In this paper, we propose the Globally Induced Forest (GIF) to remedy this
  problem. GIF is a fast prepruning approach to build lightweight ensembles by iteratively
  deepening the current forest. It mixes local and global optimizations to produce
  accurate predictions under memory constraints in reasonable time. We show that the
  proposed method is more than competitive with standard tree-based ensembles under
  corresponding constraints, and can sometimes even surpass much larger models.
layout: inproceedings
id: begon17a
tex_title: 'Globally Induced Forest: A Prepruning Compression Scheme'
firstpage: 420
lastpage: 428
page: 420-428
order: 420
cycles: false
editor:
- given: Doina
  family: Precup
- given: Yee Whye
  family: Teh
author:
- given: Jean-Michel
  family: Begon
- given: Arnaud
  family: Joly
- given: Pierre
  family: Geurts
date: 2017-07-17
container-title: Proceedings of the 34th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 7
  - 17
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v70/begon17a/begon17a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
