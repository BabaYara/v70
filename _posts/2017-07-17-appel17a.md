---
title: A Simple Multi-Class Boosting Framework with Theoretical Guarantees and Empirical
  Proficiency
booktitle: Proceedings of the 34th International Conference on Machine Learning
year: '2017'
volume: '70'
series: Proceedings of Machine Learning Research
address: 
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v70/appel17a/appel17a.pdf
url: http://proceedings.mlr.press/v70/appel17.html
abstract: There is a need for simple yet accurate white-box learning systems that
  train quickly and with little data. To this end, we showcase REBEL, a multi-class
  boosting method, and present a novel family of weak learners called localized similarities.
  Our framework provably minimizes the training error of any dataset at an exponential
  rate. We carry out experiments on a variety of synthetic and real datasets, demonstrating
  a consistent tendency to avoid overfitting. We evaluate our method on MNIST and
  standard UCI datasets against other state-of-the-art methods, showing the empirical
  proficiency of our method.
layout: inproceedings
id: appel17a
tex_title: A Simple Multi-Class Boosting Framework with Theoretical Guarantees and
  Empirical Proficiency
firstpage: 186
lastpage: 194
page: 186-194
order: 186
cycles: false
editor:
- given: Doina
  family: Precup
- given: Yee Whye
  family: Teh
author:
- given: Ron
  family: Appel
- given: Pietro
  family: Perona
date: 2017-07-17
container-title: Proceedings of the 34th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 7
  - 17
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v70/appel17a/appel17a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
